{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "important-toilet",
   "metadata": {},
   "source": [
    "# Setting up Airflow 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "atomic-checkout",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "artistic-study",
   "metadata": {},
   "source": [
    "In this lesson, we'll work with setting up airflow.  Let's get started."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "behind-nashville",
   "metadata": {},
   "source": [
    "### Setting up With Docker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "chinese-guatemala",
   "metadata": {},
   "source": [
    "The easiest way for us to get started with airflow is via Docker.  Before doing so, let's first create a folder where we can place our relevant files, and cd into that directory.\n",
    "\n",
    "```bash\n",
    "mkdir airflow-docker\n",
    "cd airflow-docker\n",
    "```\n",
    "\n",
    "From there, we can download the relevant Docker compose file located [here](https://airflow.apache.org/docs/apache-airflow/stable/docker-compose.yaml).  And we can download this by issuig the following command from the `airflow-docker` folder.\n",
    "\n",
    "```bash\n",
    "curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.0.1/docker-compose.yaml'\n",
    "```\n",
    "\n",
    "Afterwards, we should see the `docker-compose.yaml` file in our `airflow-docker` directory.\n",
    "\n",
    "> If you have trouble downloading the file using curl, you can always go to the [file](https://airflow.apache.org/docs/apache-airflow/stable/docker-compose.yaml) and then copy and paste the contents into a `docker-compose.yaml` file.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "569ce0d4-0b08-4dcf-abfa-6d606fb35849",
   "metadata": {},
   "source": [
    "### Exploring the docker-compose file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d77154f-38e2-4200-bee8-b7051c41bf0f",
   "metadata": {},
   "source": [
    "The docker-compose file can be really intimidating.  But for now the most important thing to focus on is the component that says `volumes` -- which you can see below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ba843a3-16c8-4ffc-8a0b-aa4add0cf44a",
   "metadata": {},
   "source": [
    "<img src=\"./docker-compose-file.png\" width=\"60%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4623d57-75b4-46a8-a3a1-b5e9872d7f8b",
   "metadata": {},
   "source": [
    "**First**, look for the line that says `AIRFLOW__CORE__LOAD_EXAMPLES`.  Change the value `'true'` to `'false'`.  Changing this will remove some default examples that airflow comes with, and so removing it will remove some clutter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f2df560-3a12-4134-b39e-225fd757ff7f",
   "metadata": {},
   "source": [
    "Here, in the first line down, docker will take any files in our local `dags` folder and move it into the docker container in the folder `opt/airflow/dags`.  It will do the same with logs, and plugins.  The point is that we should make these folders in our local directory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3cf3e35-2bd4-4cae-b4fd-b73f09c75136",
   "metadata": {},
   "source": [
    "<img src=\"./smaller-mkdirs.png\" width=\"50%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28e386f0-d213-4d89-8cd9-26a0ec404518",
   "metadata": {},
   "source": [
    "From there, we can boot up airflow by running the following."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a58d274-dd06-47dc-93ca-0eee21efe158",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker-compose up\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2366aa3e-cb63-4e66-95ad-c9a9e27890e7",
   "metadata": {},
   "source": [
    "It may take a couple minutes for all of the related docker containers (aka services) to boot up.  But eventually, you should be able to visit airflow by going to `localhost:8080`.\n",
    "\n",
    "> We can see that the webserver is mapped to port 8080 in the `docker-compose.yaml` file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "988c160f-2abd-435e-b17b-4814b9b8af03",
   "metadata": {},
   "source": [
    "<img src=\"./airflow-server.png\" width=\"70%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3a400b9-5f3c-48c6-a6dc-c6072d2167ca",
   "metadata": {},
   "source": [
    "> If you want to check if all containers are are running, navigate the `airflow-docker` directory, and then type in `docker-compose ps`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68aa0b61-d854-4822-92fe-29302e86dde7",
   "metadata": {},
   "source": [
    "Upon visiting airflow, login with the following credentials:\n",
    "    \n",
    "\n",
    "* username: `airflow`\n",
    "* password: `airflow`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef2c5c30-8567-4f24-a732-ae924a90cb74",
   "metadata": {},
   "source": [
    "<img src=\"./airflow-80.png\" width=\"60%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fe41e60-bb25-4987-a384-8bac0fcc7d4d",
   "metadata": {},
   "source": [
    "### Exploring the webserver"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e1c64a1-f9e6-4fc0-a98f-7f42b8593fcb",
   "metadata": {},
   "source": [
    "From here, we can look under the hood at the webserver for a bit.  We can see that the service `airflow-webserver` has the container name `airflow-docker-airflow-webserver-1`.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df01d169-5682-44fe-9a42-343257680b9e",
   "metadata": {},
   "source": [
    "<img src=\"./docker-services.png\" width=\"70%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75ad168e-84ef-4d8d-8d1c-bb8298d3116f",
   "metadata": {},
   "source": [
    "And that means that we can sh into the webserver with the following."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6fe917b-9680-4d50-a502-2d95defc2941",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker exec -it airflow-docker-airflow-webserver-1 bash\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f7748db-7f3f-471e-b9ae-a6ce6424cfe7",
   "metadata": {},
   "source": [
    "Then if we dig around, we can see that under the `/opt/airflow` folder we have our dags, logs and plugins folders."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32316ef9-eda7-4176-9d5f-24a7e81c54d8",
   "metadata": {},
   "source": [
    "<img src=\"./in-container.png\" width=\"80%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "innovative-conservation",
   "metadata": {},
   "source": [
    "### Adding a Dag"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "coordinate-grocery",
   "metadata": {},
   "source": [
    "Now let's add a dag to airflow.  We have already added the code to create our first dag in the `/dags/hello_dag.py` file in the `dags` folder of this reading.\n",
    "\n",
    "This is what it looks like."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "opposite-allen",
   "metadata": {},
   "source": [
    "```python\n",
    "# /dags/hello_dag.py\n",
    "from airflow import DAG\n",
    "from airflow.decorators import task, dag\n",
    "from airflow.utils.dates import days_ago\n",
    "from airflow.utils.task_group import TaskGroup\n",
    "\n",
    "default_args = {'start_date': days_ago(1)}\n",
    "\n",
    "\n",
    "@task\n",
    "def hello_task():\n",
    "    print('hello world')\n",
    "    return 'hello world'\n",
    "\n",
    "@dag(schedule_interval='@once', default_args=default_args, catchup=False)\n",
    "def hello_world():\n",
    "    data = hello_task()\n",
    "\n",
    "dag = hello_world()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "hungarian-jordan",
   "metadata": {},
   "source": [
    "We'll get into the details of the code later, but if we restart airflow with `docker-compose down` followed by `docker-compose up`, we should see the dag in our airflow website."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "speaking-archives",
   "metadata": {},
   "source": [
    "This time when we `bash` into our container we can see our `dags/hello_dag.py` file in our container."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "incorrect-settlement",
   "metadata": {},
   "source": [
    "<img src=\"./hello_dags.png\" width=\"100%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "recognized-machinery",
   "metadata": {},
   "source": [
    "And now we hopefully can see this dag popup if we revisit our airflow webserver by going to `localhost:8080`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bright-composition",
   "metadata": {},
   "source": [
    "There it is."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "heated-meter",
   "metadata": {},
   "source": [
    "> <img src=\"./hello_w_dag.png\" width=\"90%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "changing-potential",
   "metadata": {},
   "source": [
    "So we can see that our `hello_world` dag was uploaded.  And if we click on that `hello_world` link, then we can see that this dag consists of our `hello_task`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "secret-rings",
   "metadata": {},
   "source": [
    "<img src=\"./dag-task.png\" width=\"60%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "textile-retirement",
   "metadata": {},
   "source": [
    "Now let's try to kick off this dag.  We can do so by going back to the main airflow dashboard, flipping the switch to the left to `unpause` the dag, and then clicking the play button over to the right that says `trigger dag` when hovered over."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "pointed-childhood",
   "metadata": {},
   "source": [
    "<img src=\"./trigger_dag.png\" width=\"100%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b96e52b-68ce-45d5-aac7-5350c51db63e",
   "metadata": {},
   "source": [
    "Then press the trigger button."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77d9f626-acd2-483b-806b-2486f80af49b",
   "metadata": {},
   "source": [
    "<img src=\"./trigger.png\" width=\"60%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "surrounded-necessity",
   "metadata": {},
   "source": [
    "Then click on the green circle that says `success`.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "655aad19-666a-466f-9408-c33fc3c9a26b",
   "metadata": {},
   "source": [
    "<img src=\"./runs.png\" width=\"70%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26793ca0-2e0d-4db1-a8af-56f97e2ce3dc",
   "metadata": {},
   "source": [
    "Then click on the Dag run."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cac977e5-58b0-46d8-8dd6-1c070431fdb4",
   "metadata": {},
   "source": [
    "<img src=\"./dag_run.png\" width=\"90%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e79d530-a3f4-42e0-bbcc-28fd7593a835",
   "metadata": {},
   "source": [
    "And then click on the `hello_task`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "special-spencer",
   "metadata": {},
   "source": [
    "> <img src=\"./graph_view.png\" width=\"40%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e7c3dd3-6031-4c61-aa69-68b736c58d27",
   "metadata": {},
   "source": [
    "When we click on the hello_task, we can then click on the log."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fff59304-5648-4727-b23f-3b4bf9b04dfd",
   "metadata": {},
   "source": [
    "<img src=\"./view-log_2.png\" width=\"60%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "small-situation",
   "metadata": {},
   "source": [
    "When clicking on the button, we can indeed see the log of task being run."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ignored-charlotte",
   "metadata": {},
   "source": [
    "> <img src=\"./printed_hello.png\" width=\"100%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "existing-factor",
   "metadata": {},
   "source": [
    "Looking at the log above, we can see that we first see `Marking task as SUCCESS`.  And notice that right above that line, it says \n",
    "\n",
    "`hello world`\n",
    "\n",
    "Remember that this was the return value of the function associated with our task.\n",
    "\n",
    "```python\n",
    "def hello():\n",
    "    return 'Hello world!'\n",
    "\n",
    "hello_dag = DAG('hello_world', start_date=datetime(2021, 1, 1))\n",
    "\n",
    "hello_task = PythonOperator(task_id='hello_task', python_callable=hello, dag=hello_dag)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "mexican-deposit",
   "metadata": {},
   "source": [
    "So it looks like we were able to create a dag associated with the `hello_task`, and that the `hello_task` then called `hello` which printed out `hello world` function.  \n",
    "\n",
    "We'll go into more details about the various components of getting this to work in the following lessons, but this is a good place to stop for now."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "informative-suicide",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "american-apartment",
   "metadata": {},
   "source": [
    "In this lesson, we saw how we can get up and running with airflow by using docker.  We did booted up our airflow container with the command:\n",
    "\n",
    "\n",
    "`docker-compose up`\n",
    "\n",
    "And then we created our first dag by placing it into our `/dags` which was then mounted into our container:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "induced-omega",
   "metadata": {},
   "source": [
    "From there, we saw that our dag was uploaded to airflow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "phantom-notebook",
   "metadata": {},
   "source": [
    "> <img src=\"./hello_world.png\" width=\"80%\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "gentle-rainbow",
   "metadata": {},
   "source": [
    "And then we can manually trigger the dag -- by clicking on the play button."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "about-appendix",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Airflow Setup](https://predictivehacks.com/how-to-start-running-apache-airflow-in-docker/)\n",
    "\n",
    "[Debugging Airflow](https://www.astronomer.io/blog/7-common-errors-to-check-when-debugging-airflow-dag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
