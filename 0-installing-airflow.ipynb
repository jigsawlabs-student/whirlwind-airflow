{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "important-toilet",
   "metadata": {},
   "source": [
    "# Setting up Airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-checkout",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-study",
   "metadata": {},
   "source": [
    "In this lesson, we'll work with setting up airflow.  Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-nashville",
   "metadata": {},
   "source": [
    "### Setting up With Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-guatemala",
   "metadata": {},
   "source": [
    "The easiest way for us to get started with airflow is via Docker.  We'll be using the `puckel/docker-airflow` image available [here](https://github.com/puckel/docker-airflow).  Let's download the image by running the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-wealth",
   "metadata": {},
   "source": [
    "> `docker pull puckel/docker-airflow`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-slave",
   "metadata": {},
   "source": [
    "From there, we can confirm that our image has been downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-politics",
   "metadata": {},
   "source": [
    "<img src=\"./docker-airflow.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-group",
   "metadata": {},
   "source": [
    "Now the airflow's image contains a flask application, among other services.  And we can kick off this flask application with the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-above",
   "metadata": {},
   "source": [
    "`docker run -p 8080:8080 puckel/docker-airflow webserver`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-print",
   "metadata": {},
   "source": [
    "From there, we can view airflow by going to `localhost:8080`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-lighting",
   "metadata": {},
   "source": [
    "> <img src=\"./docker-web.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-batman",
   "metadata": {},
   "source": [
    "Looking at the website, it looks like one of the main concepts is dags.  We'll get more into dags later -- but essentially, a dag is a workflow.  It allows us to describe a series of sequential steps like extract transform and load.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-vatican",
   "metadata": {},
   "source": [
    "### Adding a DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-denial",
   "metadata": {},
   "source": [
    "We can add a dag by placing it in our airflow container.  Let's connect to our airflow and see how we can do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-silicon",
   "metadata": {},
   "source": [
    "<img src=\"./airflow-env.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-munich",
   "metadata": {},
   "source": [
    "So above, we first list the container processes, and then we sh into our running docker container.  So we can see that we are taken into the `/usr/local/airflow` folder.  And we can see that there are only a couple of files in that folder.\n",
    "\n",
    "```bash\n",
    "ls\n",
    "airflow.cfg airflow.db airflow-webserver.pid logs unittests.cfg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-turkish",
   "metadata": {},
   "source": [
    "So the `airflow.db` file is a database file for airflow.  And the `.cfg` files are configuration files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-conservation",
   "metadata": {},
   "source": [
    "### Adding a Dag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-grocery",
   "metadata": {},
   "source": [
    "Now let's add a dag to airflow.  We have already added the code to create our first dag in the `/dags/hello_dag.py` file in the `dags` folder of this reading.\n",
    "\n",
    "This is what it looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-allen",
   "metadata": {},
   "source": [
    "```python\n",
    "# /dags/hello_dag.py\n",
    "\n",
    "from datetime import datetime\n",
    "from airflow import DAG\n",
    "from airflow.operators.dummy_operator import DummyOperator\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "\n",
    "def hello():\n",
    "    return 'Hello world!'\n",
    "\n",
    "hello_dag = DAG('hello_world', start_date=datetime(2021, 1, 1))\n",
    "\n",
    "hello_task = PythonOperator(task_id='hello_task', python_callable=hello, dag=hello_dag)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-jordan",
   "metadata": {},
   "source": [
    "We'll get into the details of the code later, but for now, we can get this dag up and running by using our bindmount to place this file into the `/usr/local/airflow/dags` folder of a running airflow container.\n",
    "\n",
    "So let's first stop our running airflow container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-picture",
   "metadata": {},
   "source": [
    "And then we can run another container, this time bind-mounting the local `/dags` folder into the container's `/usr/local/airflow/dags` folder.  We do so with the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-daughter",
   "metadata": {},
   "source": [
    "```bash \n",
    "docker run -p 8080:8080 -v \"$(pwd)\"/dags:/usr/local/airflow/dags puckel/docker-airflow webserver\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-archives",
   "metadata": {},
   "source": [
    "This time when we `sh` into our container we can see our `dags/hello_dag.py` file in our container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-settlement",
   "metadata": {},
   "source": [
    "<img src=\"./hello_dags.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-machinery",
   "metadata": {},
   "source": [
    "And now we hopefully can see this dag popup if we revisit our airflow webserver by going to `localhost:8080`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-composition",
   "metadata": {},
   "source": [
    "There it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-meter",
   "metadata": {},
   "source": [
    "> <img src=\"./hello_world.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-potential",
   "metadata": {},
   "source": [
    "So we can see that our `hello_world` dag was uploaded.  And if we click on that `hello_world` link, then we can see that this dag consists of our `hello_task`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-rings",
   "metadata": {},
   "source": [
    "<img src=\"./dag-task.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-retirement",
   "metadata": {},
   "source": [
    "Now let's try to kick off this dag.  We can do so by going back to the main airflow dashboard, flipping the switch to the left to the `on` state, and then clicking the play button over to the right that says `trigger dag` when hovered over."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-childhood",
   "metadata": {},
   "source": [
    "<img src=\"./trigger-dag.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-necessity",
   "metadata": {},
   "source": [
    "If we then click on the Last Run timestamp, we'll be taken to the following screen.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-spencer",
   "metadata": {},
   "source": [
    "> <img src=\"./last-run.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-letter",
   "metadata": {},
   "source": [
    "The green border around the `hello_task` tells us that the `hello_task` was successfully run.  And then we can see further evidence of this by clicking on the task, and then clicking on the View Log button."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-ethiopia",
   "metadata": {},
   "source": [
    "> <img src=\"./view-log.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-situation",
   "metadata": {},
   "source": [
    "When clicking on the button, we can indeed see the log of task being run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-charlotte",
   "metadata": {},
   "source": [
    "> <img src=\"./log-task.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-factor",
   "metadata": {},
   "source": [
    "Looking at the log above, we can see that we first see `Starting attempt` of the task.  From ther, it says that it is running and beginning to run the task.  We then see the log of:\n",
    "\n",
    "`Done. Returned value was: Hello World!`\n",
    "\n",
    "Remember that this was the return value of the function associated with our task.\n",
    "\n",
    "```python\n",
    "def hello():\n",
    "    return 'Hello world!'\n",
    "\n",
    "hello_dag = DAG('hello_world', start_date=datetime.now())\n",
    "\n",
    "hello_task = PythonOperator(task_id='hello_task', python_callable=hello, dag=hello_dag)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-deposit",
   "metadata": {},
   "source": [
    "So it looks like we were able to create a dag associated with the `hello_task`, and that the `hello_task` then ran our `hello` function.  \n",
    "\n",
    "We'll go into more details about the various components of getting this to work in the following lessons, but this is a good place to stop for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-suicide",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-apartment",
   "metadata": {},
   "source": [
    "In this lesson, we saw how we can get up and running with airflow by using docker.  We did booted up our airflow container with the command:\n",
    "\n",
    "\n",
    "`docker run -p 8080:8080 puckel/docker-airflow webserver`\n",
    "\n",
    "And then we created our first dag by bind mounting Python code into a container's `/dags` folder with the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-timeline",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker run -p 8080:8080 -v \"$(pwd)\"/dags:/usr/local/airflow/dags puckel/docker-airflow webserver\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-omega",
   "metadata": {},
   "source": [
    "From there, we saw that our dag was uploaded to airflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-notebook",
   "metadata": {},
   "source": [
    "> <img src=\"./hello_world.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-insert",
   "metadata": {},
   "source": [
    "And from here, we can "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-rainbow",
   "metadata": {},
   "source": [
    "And then we can manually trigger the dag -- we'll describe why we need to do this in the next lesson -- by clicking on the play button."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-appendix",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Debugging Airflow](https://www.astronomer.io/blog/7-common-errors-to-check-when-debugging-airflow-dag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
